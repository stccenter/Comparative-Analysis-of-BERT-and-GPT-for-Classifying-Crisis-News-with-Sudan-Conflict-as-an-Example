{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "category_columns = [\n",
    "    \"Unlawful detention\",\n",
    "    \"Human trafficking\",\n",
    "    \"Enslavement\",\n",
    "    \"Willful killing of civilians\",\n",
    "    \"Mass execution\",\n",
    "    \"Kidnapping\",\n",
    "    \"Extrajudicial killing\",\n",
    "    \"Forced disappearance\",\n",
    "    \"Damage or destruction of civilian critical infrastructure\",\n",
    "    \"Damage or destruction, looting, or theft of cultural heritage\",\n",
    "    \"Military operations (battle, shelling)\",\n",
    "    \"Gender-based or other conflict-related sexual violence\",\n",
    "    \"Violent crackdowns on protesters/opponents/civil rights abuse\",\n",
    "    \"Indiscriminate use of weapons\",\n",
    "    \"Torture or indications of torture\",\n",
    "    \"Persecution based on political, racial, ethnic, gender, or sexual orientation\",\n",
    "    \"Movement of military, paramilitary, or other troops and equipment\"\n",
    "]\n",
    "\n",
    "# 2) Custom Dataset class for articles\n",
    "class ArticleDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "     \n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")  \n",
    "val_df   = pd.read_csv(\"val.csv\")    \n",
    "test_df  = pd.read_csv(\"test.csv\")  \n",
    "\n",
    "# Combine all datasets for k-fold cross-validation\n",
    "all_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the text columns\n",
    "train_encodings = tokenizer(\n",
    "    list(train_df[\"Incident Narrative\"].values),\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n",
    "val_encodings   = tokenizer(\n",
    "    list(val_df[\"Incident Narrative\"].values),\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n",
    "test_encodings  = tokenizer(\n",
    "    list(test_df[\"Incident Narrative\"].values),\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "# Extract labels (multi-label targets in your category columns)\n",
    "train_labels = train_df[category_columns].values\n",
    "val_labels   = val_df[category_columns].values\n",
    "test_labels  = test_df[category_columns].values\n",
    "\n",
    "# Create Dataset objects\n",
    "train_dataset = ArticleDataset(train_encodings, train_labels)\n",
    "val_dataset   = ArticleDataset(val_encodings, val_labels)\n",
    "test_dataset  = ArticleDataset(test_encodings, test_labels)\n",
    "\n",
    "     \n",
    "\n",
    "# Note: num_labels = number of category columns for multi-label classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels=len(category_columns)\n",
    ")\n",
    "\n",
    "# Define compute_metrics for multi-label classification\n",
    "def compute_metrics(p):\n",
    "    # p.predictions are logits; p.label_ids are the ground truth\n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions))  # Convert logits to probabilities\n",
    "    preds = (preds > 0.5).int().cpu().numpy() \n",
    "    labels = torch.tensor(p.label_ids).cpu().numpy()\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        average='weighted'\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='D:/Yahya/classification/results',          # Output directory\n",
    "    eval_strategy=\"epoch\",           # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",           # Save model at the end of each epoch\n",
    "    learning_rate=2e-5,              # Learning rate\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",      # Use F1 score for best model\n",
    "    logging_dir='D:/Yahya/classification/logs'\n",
    ")\n",
    "\n",
    "# Initialize Trainer with training and validation sets\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"STARTING INITIAL TRAINING\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "training_start_time = time.time()\n",
    "trainer.train()\n",
    "training_end_time = time.time()\n",
    "training_duration = training_end_time - training_start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"INITIAL TRAINING COMPLETED\")\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Training duration: {training_duration:.2f} seconds ({training_duration/60:.2f} minutes)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"D:/Yahya/classification/bert-multiclass-model\")\n",
    "\n",
    "     \n",
    "\n",
    "def evaluate_model(dataset, threshold=0.5):\n",
    "    loader = DataLoader(dataset, batch_size=16)\n",
    "    model.eval()  # Set model to eval mode\n",
    "    \n",
    "    preds_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs = {\n",
    "                key: val.to(model.device) for key, val in batch.items() if key != 'labels'\n",
    "            }\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            # Convert logits to probabilities\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            # Apply threshold\n",
    "            preds = (probs > threshold).astype(int)\n",
    "            \n",
    "            preds_list.extend(preds)\n",
    "            labels_list.extend(batch['labels'].cpu().numpy())\n",
    "    \n",
    "    preds_array = np.array(preds_list)\n",
    "    labels_array = np.array(labels_list)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels_array, preds_array, average='weighted')\n",
    "    acc = accuracy_score(labels_array, preds_array)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Run evaluation on the test dataset\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"STARTING INITIAL TEST EVALUATION\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "test_inference_start_time = time.time()\n",
    "test_results = evaluate_model(test_dataset)\n",
    "test_inference_end_time = time.time()\n",
    "test_inference_duration = test_inference_end_time - test_inference_start_time\n",
    "\n",
    "print(\"Final Test Set Evaluation Results:\", test_results)\n",
    "print(f\"Test inference duration: {test_inference_duration:.2f} seconds\")\n",
    "print(f\"Test set size: {len(test_dataset)} articles\")\n",
    "print(f\"Inference speed: {len(test_dataset)/test_inference_duration:.2f} articles/second\")\n",
    "\n",
    "# 5-Fold Cross-Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = []\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"STARTING 5-FOLD CROSS-VALIDATION\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total dataset size: {len(all_df)} articles\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "cv_start_time = time.time()\n",
    "fold_times = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(all_df)):\n",
    "    fold_start_time = time.time()\n",
    "    print(f\"\\nFold {fold + 1}/5 - Start time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"Train size: {len(train_idx)}, Test size: {len(test_idx)}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    fold_train_df = all_df.iloc[train_idx].reset_index(drop=True)\n",
    "    fold_test_df = all_df.iloc[test_idx].reset_index(drop=True)\n",
    "    \n",
    "    # Tokenize the text columns for this fold\n",
    "    fold_train_encodings = tokenizer(\n",
    "        list(fold_train_df[\"Incident Narrative\"].values),\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    fold_test_encodings = tokenizer(\n",
    "        list(fold_test_df[\"Incident Narrative\"].values),\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Extract labels for this fold\n",
    "    fold_train_labels = fold_train_df[category_columns].values\n",
    "    fold_test_labels = fold_test_df[category_columns].values\n",
    "    \n",
    "    # Create Dataset objects for this fold\n",
    "    fold_train_dataset = ArticleDataset(fold_train_encodings, fold_train_labels)\n",
    "    fold_test_dataset = ArticleDataset(fold_test_encodings, fold_test_labels)\n",
    "    \n",
    "    # Train model for this fold\n",
    "    fold_model = BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\", \n",
    "        num_labels=len(category_columns)\n",
    "    )\n",
    "    \n",
    "    fold_training_args = TrainingArguments(\n",
    "        output_dir=f'D:/Yahya/classification/fold_{fold}_results', \n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=30,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_dir=f'D:/Yahya/classification/fold_{fold}_logs',\n",
    "        disable_tqdm=True\n",
    "    )\n",
    "    \n",
    "    fold_trainer = Trainer(\n",
    "        model=fold_model,\n",
    "        args=fold_training_args,\n",
    "        train_dataset=fold_train_dataset,\n",
    "        eval_dataset=fold_test_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # Train the model for this fold\n",
    "    fold_training_start = time.time()\n",
    "    fold_trainer.train()\n",
    "    fold_training_end = time.time()\n",
    "    fold_training_duration = fold_training_end - fold_training_start\n",
    "    \n",
    "    # Evaluate on test set for this fold\n",
    "    fold_inference_start = time.time()\n",
    "    fold_results = fold_trainer.evaluate(fold_test_dataset)\n",
    "    fold_inference_end = time.time()\n",
    "    fold_inference_duration = fold_inference_end - fold_inference_start\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    fold_total_duration = fold_end_time - fold_start_time\n",
    "    fold_times.append(fold_total_duration)\n",
    "    \n",
    "    cv_results.append(fold_results)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Results:\")\n",
    "    print(f\"  Accuracy: {fold_results['eval_accuracy']:.4f}\")\n",
    "    print(f\"  F1: {fold_results['eval_f1']:.4f}\")\n",
    "    print(f\"  Precision: {fold_results['eval_precision']:.4f}\")\n",
    "    print(f\"  Recall: {fold_results['eval_recall']:.4f}\")\n",
    "    print(f\"  Training time: {fold_training_duration:.2f} seconds ({fold_training_duration/60:.2f} minutes)\")\n",
    "    print(f\"  Inference time: {fold_inference_duration:.2f} seconds\")\n",
    "    print(f\"  Total fold time: {fold_total_duration:.2f} seconds ({fold_total_duration/60:.2f} minutes)\")\n",
    "    print(f\"  Inference speed: {len(fold_test_dataset)/fold_inference_duration:.2f} articles/second\")\n",
    "\n",
    "cv_end_time = time.time()\n",
    "cv_total_duration = cv_end_time - cv_start_time\n",
    "\n",
    "# Calculate and display cross-validation statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"5-FOLD CROSS-VALIDATION RESULTS\")\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total CV duration: {cv_total_duration:.2f} seconds ({cv_total_duration/60:.2f} minutes)\")\n",
    "print(f\"Average time per fold: {np.mean(fold_times):.2f} seconds ({np.mean(fold_times)/60:.2f} minutes)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "cv_accuracy = [result['eval_accuracy'] for result in cv_results]\n",
    "cv_f1 = [result['eval_f1'] for result in cv_results]\n",
    "cv_precision = [result['eval_precision'] for result in cv_results]\n",
    "cv_recall = [result['eval_recall'] for result in cv_results]\n",
    "\n",
    "print(f\"Accuracy: {np.mean(cv_accuracy):.4f} ± {np.std(cv_accuracy):.4f}\")\n",
    "print(f\"F1 Score: {np.mean(cv_f1):.4f} ± {np.std(cv_f1):.4f}\")\n",
    "print(f\"Precision: {np.mean(cv_precision):.4f} ± {np.std(cv_precision):.4f}\")\n",
    "print(f\"Recall: {np.mean(cv_recall):.4f} ± {np.std(cv_recall):.4f}\")\n",
    "\n",
    "print(f\"\\nIndividual Fold Results:\")\n",
    "for i, result in enumerate(cv_results):\n",
    "    print(f\"Fold {i+1}: Acc={result['eval_accuracy']:.4f}, F1={result['eval_f1']:.4f}, \"\n",
    "          f\"Prec={result['eval_precision']:.4f}, Rec={result['eval_recall']:.4f}, Time={fold_times[i]/60:.2f}min\")\n",
    "\n",
    "print(f\"\\nNote: Cross-validation addresses the limitation of the original 90%/10% split\")\n",
    "print(f\"which resulted in only 43 test articles. This approach uses all {len(all_df)} articles\")\n",
    "print(f\"for evaluation across 5 folds, providing more robust statistical significance.\")\n",
    "\n",
    "# Save cross-validation results to file\n",
    "cv_summary = {\n",
    "    'Mean_Accuracy': np.mean(cv_accuracy),\n",
    "    'Std_Accuracy': np.std(cv_accuracy),\n",
    "    'Mean_F1': np.mean(cv_f1),\n",
    "    'Std_F1': np.std(cv_f1),\n",
    "    'Mean_Precision': np.mean(cv_precision),\n",
    "    'Std_Precision': np.std(cv_precision),\n",
    "    'Mean_Recall': np.mean(cv_recall),\n",
    "    'Std_Recall': np.std(cv_recall),\n",
    "    'Initial_Training_Time_Seconds': training_duration,\n",
    "    'Initial_Training_Time_Minutes': training_duration/60,\n",
    "    'Test_Inference_Time_Seconds': test_inference_duration,\n",
    "    'Test_Inference_Speed_Articles_Per_Second': len(test_dataset)/test_inference_duration,\n",
    "    'CV_Total_Time_Seconds': cv_total_duration,\n",
    "    'CV_Total_Time_Minutes': cv_total_duration/60,\n",
    "    'CV_Average_Fold_Time_Seconds': np.mean(fold_times),\n",
    "    'CV_Average_Fold_Time_Minutes': np.mean(fold_times)/60,\n",
    "    'Total_Articles': len(all_df),\n",
    "    'Test_Set_Size': len(test_dataset),\n",
    "    'Experiment_Date': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'Experiment_Time': datetime.now().strftime('%H:%M:%S')\n",
    "}\n",
    "\n",
    "cv_summary_df = pd.DataFrame([cv_summary])\n",
    "cv_summary_df.to_csv(\"D:/Yahya/classification/cv_results_summary.csv\", index=False)\n",
    "\n",
    "print(f\"\\nCross-validation results saved to: D:/Yahya/classification/cv_results_summary.csv\")\n",
    "\n",
    "# Print final timing summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FINAL TIMING SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Initial Training Time: {training_duration/60:.2f} minutes\")\n",
    "print(f\"Initial Test Inference Time: {test_inference_duration:.2f} seconds\")\n",
    "print(f\"5-Fold CV Total Time: {cv_total_duration/60:.2f} minutes\")\n",
    "print(f\"Total Experiment Time: {(training_duration + test_inference_duration + cv_total_duration)/60:.2f} minutes\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
