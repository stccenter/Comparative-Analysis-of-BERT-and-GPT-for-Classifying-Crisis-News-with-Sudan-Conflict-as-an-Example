{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "########################\n",
    "# 1) Device Setup      #\n",
    "########################\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "########################\n",
    "# 2) Data + Categories #\n",
    "########################\n",
    "\n",
    "category_columns = [\n",
    "    \"Unlawful detention\",\n",
    "    \"Human trafficking\",\n",
    "    \"Enslavement\",\n",
    "    \"Willful killing of civilians\",\n",
    "    \"Mass execution\",\n",
    "    \"Kidnapping\",\n",
    "    \"Extrajudicial killing\",\n",
    "    \"Forced disappearance\",\n",
    "    \"Damage or destruction of civilian critical infrastructure\",\n",
    "    \"Damage or destruction, looting, or theft of cultural heritage\",\n",
    "    \"Military operations (battle, shelling)\",\n",
    "    \"Gender-based or other conflict-related sexual violence\",\n",
    "    \"Violent crackdowns on protesters/opponents/civil rights abuse\",\n",
    "    \"Indiscriminate use of weapons\",\n",
    "    \"Torture or indications of torture\",\n",
    "    \"Persecution based on political, racial, ethnic, gender, or sexual orientation\",\n",
    "    \"Movement of military, paramilitary, or other troops and equipment\"\n",
    "]\n",
    "\n",
    "# Load CSVs (adjust to your actual file paths)\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "val_df   = pd.read_csv(\"val.csv\")\n",
    "test_df  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Combine all datasets for k-fold cross-validation\n",
    "all_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "##################################\n",
    "# 3) Custom Dataset for Articles #\n",
    "##################################\n",
    "\n",
    "class ArticleDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "###############################\n",
    "# 4) Tokenization + Datasets #\n",
    "###############################\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize (Incident Narrative column)\n",
    "train_encodings = tokenizer(\n",
    "    list(train_df[\"Incident Narrative\"].values),\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n",
    "val_encodings   = tokenizer(\n",
    "    list(val_df[\"Incident Narrative\"].values),\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n",
    "test_encodings  = tokenizer(\n",
    "    list(test_df[\"Incident Narrative\"].values),\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "# Extract labels (multi-hot vectors for each category)\n",
    "train_labels = train_df[category_columns].values\n",
    "val_labels   = val_df[category_columns].values\n",
    "test_labels  = test_df[category_columns].values\n",
    "\n",
    "# Create Dataset objects\n",
    "train_dataset = ArticleDataset(train_encodings, train_labels)\n",
    "val_dataset   = ArticleDataset(val_encodings, val_labels)\n",
    "test_dataset  = ArticleDataset(test_encodings, test_labels)\n",
    "\n",
    "########################\n",
    "# 5) Model + Training  #\n",
    "########################\n",
    "\n",
    "# num_labels = number of category columns\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(category_columns)\n",
    ")\n",
    "\n",
    "# Move the model to the correct device\n",
    "model.to(device)\n",
    "\n",
    "# Define compute_metrics for multi-label classification\n",
    "def compute_metrics(p):\n",
    "    # p.predictions are logits; p.label_ids are ground truth\n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions))  # Convert logits to probabilities\n",
    "    preds = (preds > 0.5).int().cpu().numpy()\n",
    "    labels = torch.tensor(p.label_ids).cpu().numpy()\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='weighted'\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='D:/Yahya/classification/results',         # Output directory\n",
    "    eval_strategy=\"epoch\",          # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",          # Save model at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",     # Use F1 score for best model\n",
    "    logging_dir='D:/Yahya/classification/logs'\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"STARTING INITIAL TRAINING\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "training_start_time = time.time()\n",
    "trainer.train()\n",
    "training_end_time = time.time()\n",
    "training_duration = training_end_time - training_start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"INITIAL TRAINING COMPLETED\")\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Training duration: {training_duration:.2f} seconds ({training_duration/60:.2f} minutes)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"D:/Yahya/classification/bert-multiclass-model\")\n",
    "\n",
    "###########################################\n",
    "# 6) Single-Category Inference on Test Set\n",
    "###########################################\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"STARTING INITIAL TEST EVALUATION\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "test_inference_start_time = time.time()\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,  # Adjust as appropriate\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model.eval()  # evaluation mode\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move batch inputs/labels to the same device as the model\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(**inputs)   # forward pass\n",
    "        logits = outputs.logits     # shape: (batch_size, 17)\n",
    "\n",
    "        # Convert to numpy\n",
    "        probs = logits.detach().cpu().numpy()\n",
    "\n",
    "        y_true.extend(labels.detach().cpu().numpy())\n",
    "        y_pred.extend(probs)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_true = np.array(y_true)  # shape: (num_samples, 17)\n",
    "y_pred = np.array(y_pred)  # shape: (num_samples, 17)\n",
    "\n",
    "# 1) Single-label by argmax\n",
    "y_pred_single = np.argmax(y_pred, axis=1)  # shape: (num_samples,)\n",
    "\n",
    "# 2) Exact-match accuracy if predicted category is among the \"1\"s in ground truth\n",
    "accuracy = np.mean([\n",
    "    1 if y_true[i, y_pred_single[i]] == 1 else 0\n",
    "    for i in range(len(y_true))\n",
    "])\n",
    "\n",
    "test_inference_end_time = time.time()\n",
    "test_inference_duration = test_inference_end_time - test_inference_start_time\n",
    "\n",
    "print(\"Exact-match single-category accuracy:\", accuracy)\n",
    "print(f\"Test inference duration: {test_inference_duration:.2f} seconds\")\n",
    "print(f\"Test set size: {len(test_dataset)} articles\")\n",
    "print(f\"Inference speed: {len(test_dataset)/test_inference_duration:.2f} articles/second\")\n",
    "\n",
    "# 5-Fold Cross-Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = []\n",
    "cv_single_accuracies = []\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"STARTING 5-FOLD CROSS-VALIDATION\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total dataset size: {len(all_df)} articles\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "cv_start_time = time.time()\n",
    "fold_times = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(all_df)):\n",
    "    fold_start_time = time.time()\n",
    "    print(f\"\\nFold {fold + 1}/5 - Start time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"Train size: {len(train_idx)}, Test size: {len(test_idx)}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    fold_train_df = all_df.iloc[train_idx].reset_index(drop=True)\n",
    "    fold_test_df = all_df.iloc[test_idx].reset_index(drop=True)\n",
    "    \n",
    "    # Tokenize the text columns for this fold\n",
    "    fold_train_encodings = tokenizer(\n",
    "        list(fold_train_df[\"Incident Narrative\"].values),\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    fold_test_encodings = tokenizer(\n",
    "        list(fold_test_df[\"Incident Narrative\"].values),\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Extract labels for this fold\n",
    "    fold_train_labels = fold_train_df[category_columns].values\n",
    "    fold_test_labels = fold_test_df[category_columns].values\n",
    "    \n",
    "    # Create Dataset objects for this fold\n",
    "    fold_train_dataset = ArticleDataset(fold_train_encodings, fold_train_labels)\n",
    "    fold_test_dataset = ArticleDataset(fold_test_encodings, fold_test_labels)\n",
    "    \n",
    "    # Train model for this fold\n",
    "    fold_model = BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\", \n",
    "        num_labels=len(category_columns)\n",
    "    )\n",
    "    fold_model.to(device)\n",
    "    \n",
    "    fold_training_args = TrainingArguments(\n",
    "        output_dir=f'D:/Yahya/classification/fold_{fold}_results', \n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=30,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        logging_dir=f'D:/Yahya/classification/fold_{fold}_logs',\n",
    "        disable_tqdm=True\n",
    "    )\n",
    "    \n",
    "    fold_trainer = Trainer(\n",
    "        model=fold_model,\n",
    "        args=fold_training_args,\n",
    "        train_dataset=fold_train_dataset,\n",
    "        eval_dataset=fold_test_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # Train the model for this fold\n",
    "    fold_training_start = time.time()\n",
    "    fold_trainer.train()\n",
    "    fold_training_end = time.time()\n",
    "    fold_training_duration = fold_training_end - fold_training_start\n",
    "    \n",
    "    # Evaluate on test set for this fold (multi-label metrics)\n",
    "    fold_inference_start = time.time()\n",
    "    fold_results = fold_trainer.evaluate(fold_test_dataset)\n",
    "    \n",
    "    # Single-category inference for this fold\n",
    "    fold_test_loader = DataLoader(fold_test_dataset, batch_size=16, shuffle=False)\n",
    "    fold_model.eval()\n",
    "    \n",
    "    fold_y_true = []\n",
    "    fold_y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in fold_test_loader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = fold_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = logits.detach().cpu().numpy()\n",
    "            \n",
    "            fold_y_true.extend(labels.detach().cpu().numpy())\n",
    "            fold_y_pred.extend(probs)\n",
    "    \n",
    "    # Convert to numpy arrays for this fold\n",
    "    fold_y_true = np.array(fold_y_true)\n",
    "    fold_y_pred = np.array(fold_y_pred)\n",
    "    \n",
    "    # Single-label by argmax for this fold\n",
    "    fold_y_pred_single = np.argmax(fold_y_pred, axis=1)\n",
    "    \n",
    "    # Exact-match accuracy for this fold\n",
    "    fold_single_accuracy = np.mean([\n",
    "        1 if fold_y_true[i, fold_y_pred_single[i]] == 1 else 0\n",
    "        for i in range(len(fold_y_true))\n",
    "    ])\n",
    "    \n",
    "    fold_inference_end = time.time()\n",
    "    fold_inference_duration = fold_inference_end - fold_inference_start\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    fold_total_duration = fold_end_time - fold_start_time\n",
    "    fold_times.append(fold_total_duration)\n",
    "    \n",
    "    cv_results.append(fold_results)\n",
    "    cv_single_accuracies.append(fold_single_accuracy)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Results:\")\n",
    "    print(f\"  Multi-label Accuracy: {fold_results['eval_accuracy']:.4f}\")\n",
    "    print(f\"  Multi-label F1: {fold_results['eval_f1']:.4f}\")\n",
    "    print(f\"  Multi-label Precision: {fold_results['eval_precision']:.4f}\")\n",
    "    print(f\"  Multi-label Recall: {fold_results['eval_recall']:.4f}\")\n",
    "    print(f\"  Single-category Accuracy: {fold_single_accuracy:.4f}\")\n",
    "    print(f\"  Training time: {fold_training_duration:.2f} seconds ({fold_training_duration/60:.2f} minutes)\")\n",
    "    print(f\"  Inference time: {fold_inference_duration:.2f} seconds\")\n",
    "    print(f\"  Total fold time: {fold_total_duration:.2f} seconds ({fold_total_duration/60:.2f} minutes)\")\n",
    "    print(f\"  Inference speed: {len(fold_test_dataset)/fold_inference_duration:.2f} articles/second\")\n",
    "\n",
    "cv_end_time = time.time()\n",
    "cv_total_duration = cv_end_time - cv_start_time\n",
    "\n",
    "# Calculate and display cross-validation statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"5-FOLD CROSS-VALIDATION RESULTS\")\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total CV duration: {cv_total_duration:.2f} seconds ({cv_total_duration/60:.2f} minutes)\")\n",
    "print(f\"Average time per fold: {np.mean(fold_times):.2f} seconds ({np.mean(fold_times)/60:.2f} minutes)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "cv_accuracy = [result['eval_accuracy'] for result in cv_results]\n",
    "cv_f1 = [result['eval_f1'] for result in cv_results]\n",
    "cv_precision = [result['eval_precision'] for result in cv_results]\n",
    "cv_recall = [result['eval_recall'] for result in cv_results]\n",
    "\n",
    "print(\"MULTI-LABEL RESULTS:\")\n",
    "print(f\"Accuracy: {np.mean(cv_accuracy):.4f} ± {np.std(cv_accuracy):.4f}\")\n",
    "print(f\"F1 Score: {np.mean(cv_f1):.4f} ± {np.std(cv_f1):.4f}\")\n",
    "print(f\"Precision: {np.mean(cv_precision):.4f} ± {np.std(cv_precision):.4f}\")\n",
    "print(f\"Recall: {np.mean(cv_recall):.4f} ± {np.std(cv_recall):.4f}\")\n",
    "\n",
    "print(\"\\nSINGLE-CATEGORY RESULTS:\")\n",
    "print(f\"Exact-match Accuracy: {np.mean(cv_single_accuracies):.4f} ± {np.std(cv_single_accuracies):.4f}\")\n",
    "\n",
    "print(f\"\\nIndividual Fold Results:\")\n",
    "for i, result in enumerate(cv_results):\n",
    "    print(f\"Fold {i+1}: Multi-Acc={result['eval_accuracy']:.4f}, Multi-F1={result['eval_f1']:.4f}, \"\n",
    "          f\"Single-Acc={cv_single_accuracies[i]:.4f}, Time={fold_times[i]/60:.2f}min\")\n",
    "\n",
    "print(f\"\\nNote: Cross-validation addresses the limitation of the original 90%/10% split\")\n",
    "print(f\"which resulted in only 43 test articles. This approach uses all {len(all_df)} articles\")\n",
    "print(f\"for evaluation across 5 folds, providing more robust statistical significance.\")\n",
    "\n",
    "# Save cross-validation results to file\n",
    "cv_summary = {\n",
    "    'Mean_MultiLabel_Accuracy': np.mean(cv_accuracy),\n",
    "    'Std_MultiLabel_Accuracy': np.std(cv_accuracy),\n",
    "    'Mean_MultiLabel_F1': np.mean(cv_f1),\n",
    "    'Std_MultiLabel_F1': np.std(cv_f1),\n",
    "    'Mean_MultiLabel_Precision': np.mean(cv_precision),\n",
    "    'Std_MultiLabel_Precision': np.std(cv_precision),\n",
    "    'Mean_MultiLabel_Recall': np.mean(cv_recall),\n",
    "    'Std_MultiLabel_Recall': np.std(cv_recall),\n",
    "    'Mean_SingleCategory_Accuracy': np.mean(cv_single_accuracies),\n",
    "    'Std_SingleCategory_Accuracy': np.std(cv_single_accuracies),\n",
    "    'Initial_SingleCategory_Accuracy': accuracy,\n",
    "    'Initial_Training_Time_Seconds': training_duration,\n",
    "    'Initial_Training_Time_Minutes': training_duration/60,\n",
    "    'Test_Inference_Time_Seconds': test_inference_duration,\n",
    "    'Test_Inference_Speed_Articles_Per_Second': len(test_dataset)/test_inference_duration,\n",
    "    'CV_Total_Time_Seconds': cv_total_duration,\n",
    "    'CV_Total_Time_Minutes': cv_total_duration/60,\n",
    "    'CV_Average_Fold_Time_Seconds': np.mean(fold_times),\n",
    "    'CV_Average_Fold_Time_Minutes': np.mean(fold_times)/60,\n",
    "    'Total_Articles': len(all_df),\n",
    "    'Test_Set_Size': len(test_dataset),\n",
    "    'Experiment_Date': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'Experiment_Time': datetime.now().strftime('%H:%M:%S')\n",
    "}\n",
    "\n",
    "cv_summary_df = pd.DataFrame([cv_summary])\n",
    "cv_summary_df.to_csv(\"D:/Yahya/classification/cv_results_summary_single_category.csv\", index=False)\n",
    "\n",
    "print(f\"\\nCross-validation results saved to: D:/Yahya/classification/cv_results_summary_single_category.csv\")\n",
    "\n",
    "# Print final timing summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FINAL TIMING SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Initial Training Time: {training_duration/60:.2f} minutes\")\n",
    "print(f\"Initial Test Inference Time: {test_inference_duration:.2f} seconds\")\n",
    "print(f\"5-Fold CV Total Time: {cv_total_duration/60:.2f} minutes\")\n",
    "print(f\"Total Experiment Time: {(training_duration + test_inference_duration + cv_total_duration)/60:.2f} minutes\")\n",
    "print(f\"Initial Single-Category Accuracy: {accuracy:.4f}\")\n",
    "print(f\"CV Single-Category Accuracy: {np.mean(cv_single_accuracies):.4f} ± {np.std(cv_single_accuracies):.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
